{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253ae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import math\n",
    "from tensorflow.keras import backend as K\n",
    "import sys\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba65af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0f7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0f725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.train_mask_loss = keras.metrics.Mean(name=\"train_mask_loss\")\n",
    "        self.val_mask_loss = keras.metrics.Mean(name=\"val_mask_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.kl_weight = 0.0\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.train_mask_loss,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def reconstruction_loss(self, true_masks, pred_masks, z_mean, z_logvar, z_latent):\n",
    "    \n",
    "        kl_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(tf.exp(z_logvar)) - 2*(z_logvar) - 1,\n",
    "                                                     axis=1))\n",
    "        mask_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(true_masks,pred_masks))\n",
    "\n",
    "        return mask_loss, kl_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (bx, cls, mask) = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z_latent = self.encoder(data)\n",
    "            pred_mask = self.decoder((bx, cls, z_latent))\n",
    "            mask_loss, kl_loss = self.reconstruction_loss(mask, pred_mask, z_mean, z_log_var, z_latent)\n",
    "            total_loss = mask_loss + kl_loss*self.kl_weight\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.train_mask_loss.update_state(mask_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "#         self.update_kl_weight()\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"mask_loss\": self.train_mask_loss.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        \n",
    "        z_mean, z_log_var, z_latent = self.encoder(data)\n",
    "        (bx, cls, mask) = data[0]\n",
    "        pred_mask = self.decoder((bx, cls, z_latent))\n",
    "        mask_loss, kl_loss = self.reconstruction_loss(mask, pred_mask, z_mean, z_log_var, z_latent)\n",
    "        total_loss = mask_loss + kl_loss*self.kl_weight\n",
    "        self.val_mask_loss.update_state(mask_loss)\n",
    "        return {\n",
    "            \"mask_loss\": self.val_mask_loss.result(),\n",
    "        }\n",
    "    \n",
    "    def generate(self, bbx_cond, class_cond):\n",
    "        \n",
    "        batch = len(bbx_cond)\n",
    "        dim = 64\n",
    "        z_latent = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        pred_mask = self.decoder((bbx_cond, class_cond, z_latent))\n",
    "        \n",
    "        return pred_mask\n",
    "    \n",
    "    def reconstruct(self, data):\n",
    "        \n",
    "        z_mean, z_log_var, z_latent = self.encoder(data)\n",
    "        (bx, cls, mask) = data[0]\n",
    "        pred_mask = self.decoder((bx, cls, z_latent))\n",
    "        \n",
    "        return pred_mask\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def update_kl_weight(self):\n",
    "        if (self.kl_loss_tracker.result() > 10.0 \n",
    "            and abs(self.train_mask_loss.result() - self.val_mask_loss.result())< 0.1 \n",
    "            and self.kl_weight<0.5):\n",
    "            self.kl_weight += 0.01 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3f0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_postfix):\n",
    "    \n",
    "    outfile = 'C:/GitHub/meronymnet/data_np_16/X_train'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        X_train = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'C:/GitHub/meronymnet/data_np_16/class_v'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        class_v = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'C:/GitHub/meronymnet/data_np_16/masks_train'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        masks = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'C:/GitHub/meronymnet/data_np_16/X_train_val'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        X_train_val = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'C:/GitHub/meronymnet/data_np_16/class_v_val'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        class_v_val = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'C:/GitHub/meronymnet/data_np_16/masks_val'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        masks_val = pickle.load(pickle_file)\n",
    "\n",
    "     #outfile = 'C:/GitHub/meronymnet/data_np_16/X_test'+file_postfix+'.np'\n",
    "     #with open(outfile, 'rb') as pickle_file:\n",
    "     #    X_test = pickle.load(pickle_file)\n",
    "\n",
    "     #outfile = 'C:/GitHub/meronymnet/data_np_16/X_test'+file_postfix+'.np'\n",
    "     #with open(outfile, 'rb') as pickle_file:\n",
    "     #    X_obj_test = pickle.load(pickle_file)\n",
    "        \n",
    "        \n",
    "    return X_train, class_v, masks, X_train_val, class_v_val, masks_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98aaf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_latent(a, b, c, d=None):\n",
    "    p = np.random.permutation(len(a))\n",
    "    if d is None:\n",
    "        return a[p], b[p], c[p]\n",
    "    return a[p], b[p], c[p], d[p]\n",
    "\n",
    "def sampling(z_mean, z_log_var):\n",
    "    epsilon = tf.random_normal(tf.shape(z_log_var), name=\"epsilon\")\n",
    "    return z_mean + epsilon * tf.exp(z_log_var)\n",
    "\n",
    "def frange_cycle_linear(n_iter, start=0.0, stop=1.0,  n_cycle=4, ratio=0.5):\n",
    "    L = np.ones(n_iter) * stop\n",
    "    period = n_iter/n_cycle\n",
    "    step = (stop-start)/(period*ratio)\n",
    "\n",
    "    for c in range(n_cycle):\n",
    "        v, i = start, 0\n",
    "        while v <= stop and (int(i+c*period) < n_iter):\n",
    "            L[int(i+c*period)] = v\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86301980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(true_masks, pred_masks, z_mean, z_logvar, z_latent):\n",
    "    \n",
    "    kl_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(tf.exp(z_logvar)) - 2*(z_logvar) - 1,\n",
    "                                                 axis=1))  \n",
    "    mask_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(true_masks,pred_masks))\n",
    "\n",
    "    return mask_loss, kl_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c591a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "max_num_node = 16\n",
    "latent_dims = 64\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dims,))\n",
    "\n",
    "true_maps = keras.Input(shape=([max_num_node, 64, 64, 1]), dtype=tf.float32)\n",
    "true_masks = keras.Input(shape=([max_num_node, 64, 64, 1]), dtype=tf.float32)\n",
    "true_edges = keras.Input(shape=([max_num_node, 64, 64, 1]), dtype=tf.float32)\n",
    "\n",
    "true_bbxs = keras.Input(shape=([max_num_node, 4]), dtype=tf.float32)\n",
    "cond_bbxs = keras.Input(shape=([max_num_node, 4]), dtype=tf.int32)\n",
    "\n",
    "true_lbls = keras.Input(shape=([max_num_node, 1]), dtype=tf.float32)\n",
    "cond_lbls = keras.Input(shape=([max_num_node, 1]), dtype=tf.float32)\n",
    "\n",
    "true_classes = keras.Input(shape=([7]), dtype=tf.float32)\n",
    "cond_classes = keras.Input(shape=([7]), dtype=tf.float32)\n",
    "\n",
    "\n",
    "rnn_bbxs = layers.Bidirectional(layers.GRU(4, return_sequences=True))(true_bbxs)\n",
    "concatenated_bbx_lbl = rnn_bbxs\n",
    "dense_cond = layers.Dense(64, activation='tanh')(true_classes)\n",
    "enc = layers.TimeDistributed(layers.Conv2D(8, kernel_size=3))(true_masks)\n",
    "enc = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(enc)\n",
    "enc = layers.TimeDistributed(layers.Activation('relu'))(enc)\n",
    "\n",
    "enc = layers.TimeDistributed(layers.Conv2D(16, kernel_size=3))(enc)\n",
    "enc = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(enc)\n",
    "enc = layers.TimeDistributed(layers.Activation('relu'))(enc)\n",
    "\n",
    "enc = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(enc)\n",
    "\n",
    "enc = layers.TimeDistributed(layers.Conv2D(32, kernel_size=3, activation='relu'))(enc)\n",
    "enc = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(enc)\n",
    "enc = layers.TimeDistributed(layers.Activation('relu'))(enc)\n",
    "enc = layers.TimeDistributed(layers.Flatten())(enc)\n",
    "TDD = layers.TimeDistributed(layers.Dense(64, activation='relu', name = 'encoded_bitmaps'))\n",
    "dense_enc_maps = TDD(enc)\n",
    "\n",
    "BGRU = layers.Bidirectional(layers.GRU(32, return_sequences=True))\n",
    "rnn_maps = BGRU(dense_enc_maps)\n",
    "\n",
    "D = layers.Dense(64, activation='tanh')\n",
    "attention = D(concatenated_bbx_lbl)\n",
    "sent_representation = layers.Multiply()([rnn_maps, attention])\n",
    "sent_representation = layers.Multiply()([sent_representation, dense_cond])\n",
    "images_with_attention = layers.Lambda(lambda xin: K.sum(xin, axis=-2),\n",
    "                                            output_shape=(128,))(sent_representation)\n",
    "\n",
    "z_mean = layers.Dense(64, activation='tanh')(images_with_attention)\n",
    "z_log_var = layers.Dense(64, activation='tanh', name='z_logvar')(images_with_attention)\n",
    "\n",
    "z_latent = z_mean #sampling(z_mean, z_log_var)\n",
    "#z_latent = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=[true_bbxs, true_classes, true_masks],\n",
    "                      outputs=[z_mean, z_log_var, z_latent], \n",
    "                      name='encoder')\n",
    "\n",
    "# Decoder\n",
    "cond_bbx = layers.Lambda(lambda xin: K.sum(xin, axis=-1), output_shape=(4,))(cond_bbxs)\n",
    "cond_cat = cond_bbx\n",
    "\n",
    "cond_fully_cat = layers.Dense(64, activation='relu')(cond_cat)\n",
    "cond_class_ = layers.Dense(64, activation='relu')(cond_classes)\n",
    "conditioned_z = layers.concatenate([cond_fully_cat, latent_inputs], axis=-1, name='conditioned_z_1')\n",
    "conditioned_z = layers.concatenate([conditioned_z, cond_class_], axis=-1, name='conditioned_z_2')\n",
    "decoded = layers.RepeatVector(max_num_node)(conditioned_z)\n",
    "decoded = layers.Bidirectional(layers.GRU(32, return_sequences=True))(decoded)\n",
    "dec_dense = layers.TimeDistributed(layers.Dense(25088, activation='relu',  name = 'encoding'))(decoded)\n",
    "dec_conv = layers.TimeDistributed(layers.Reshape((28, 28, 32)))(dec_dense)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.Conv2DTranspose(32, kernel_size=3, padding='same'))(dec_conv)\n",
    "dec = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(dec)\n",
    "dec = layers.TimeDistributed(layers.Activation('relu'))(dec)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.Conv2DTranspose(16, kernel_size=3))(dec)\n",
    "dec = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(dec)\n",
    "dec = layers.TimeDistributed(layers.Activation('relu'))(dec)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.UpSampling2D(size=(2, 2)))(dec)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.Conv2DTranspose(8, kernel_size=3))(dec)\n",
    "dec = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(dec)\n",
    "dec = layers.TimeDistributed(layers.Activation('relu'))(dec)\n",
    "\n",
    "decoder_bitmaps = layers.TimeDistributed(layers.Conv2DTranspose(1, kernel_size=3,\n",
    "                                                                            activation='sigmoid', \n",
    "                                                                            name = 'decoded_mask'))(dec)\n",
    "decoder = keras.Model(inputs=[cond_bbxs, cond_classes, latent_inputs],\n",
    "                      outputs=decoder_bitmaps, \n",
    "                      name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a245ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  9/213 [>.............................] - ETA: 10s - loss: 0.6933 - mask_loss: 0.6933 - kl_loss: 0.0020WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.maskVAE object at 0x000002218B0ECD00>, because it is not built.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model <__main__.maskVAE object at 0x000002218B0ECD00> cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     18\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     19\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     20\u001b[0m         filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00002/maskvae.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m         save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m     22\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(scheduler)]\n\u001b[0;32m     24\u001b[0m mask_vae_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(lr))\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmask_vae_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_v_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\saving\\saving_utils.py:97\u001b[0m, in \u001b[0;36mraise_model_input_error\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be saved because the input shape is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable. Please specify an input shape either by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`build(input_shape)` directly, or by calling the model on actual \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata using `Model()`, `Model.fit()`, or `Model.predict()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# If the model is not a `Sequential`, it is intended to be a subclassed\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be saved either because the input shape is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable or because the forward pass of the model is not defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo define a forward pass, please override `Model.call()`. To specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man input shape, either call `build(input_shape)` directly, or call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on actual data using `Model()`, `Model.fit()`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.predict()`. If you have a custom training step, please make \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msure to invoke the forward pass in train step through \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Model <__main__.maskVAE object at 0x000002218B0ECD00> cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`."
     ]
    }
   ],
   "source": [
    "lr = 0.00002\n",
    "file_postfix = '_combined_mask_data'\n",
    "\n",
    "mask_vae_model = maskVAE(encoder, decoder)\n",
    "X_train, class_v, masks, X_train_val, class_v_val, masks_val = load_data(file_postfix)\n",
    "gc.collect()\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train[:,:,1:], class_v, masks))\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((X_train_val[:,:,1:], class_v_val, masks_val))\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch%10==0:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    else:\n",
    "        return lr\n",
    "    \n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"D:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00002/maskvae.ckpt\",\n",
    "        save_freq=10),\n",
    "    tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
    "\n",
    "mask_vae_model.compile(optimizer=keras.optimizers.Adam(lr))\n",
    "mask_vae_model.fit(((X_train[:,:,1:], class_v, masks)),\n",
    "                   epochs=200, batch_size=16, \n",
    "                   validation_data=((X_train_val[:,:,1:], class_v_val, masks_val),),\n",
    "                   callbacks=callbacks, \n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a249a9-2664-4ba7-8c2a-f87b12f5c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"C:/MeronymNet-PyTorch/src/mask_generation_model_tf2_reconstruction/lr00002/maskvae.ckpt\"\n",
    "mask_vae_model.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc9a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_masks = []\n",
    "batch_size = 100\n",
    "for i in range(len(X_train_val)//batch_size):\n",
    "    generated_masks.append(\n",
    "        mask_vae_model.reconstruct(\n",
    "            (\n",
    "                np.float32(X_train_val[i:batch_size*(i+1),:,1:]),\n",
    "                np.float32(class_v_val[i:batch_size*(i+1)])\n",
    "                np.float32(masks_val[i:batch_size*(i+1)])\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27e4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outfile = 'D:/meronym_data/generated_masks.npy'\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    generated_masks = np.concatenate(generated_masks)\n",
    "    pickle.dump(generated_masks, pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
