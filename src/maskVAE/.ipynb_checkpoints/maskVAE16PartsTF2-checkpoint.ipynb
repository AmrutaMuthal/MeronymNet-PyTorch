{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253ae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "# import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# import keras\n",
    "import pickle\n",
    "import math\n",
    "from tensorflow.keras import backend as K\n",
    "import sys\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e3d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3f0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_postfix):\n",
    "    \n",
    "    outfile = 'D:/meronym_data/X_train'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        X_train = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'D:/meronym_data/class_v'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        class_v = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'D:/meronym_data/masks_train'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        masks = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'D:/meronym_data/X_val'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        X_train_val = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'D:/meronym_data/class_v_val'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        class_v_val = pickle.load(pickle_file)\n",
    "\n",
    "    outfile = 'D:/meronym_data/masks_val'+file_postfix+'.np'\n",
    "    with open(outfile, 'rb') as pickle_file:\n",
    "        masks_val = pickle.load(pickle_file)\n",
    "\n",
    "#     outfile = 'D:/meronym_data/X_test'+part_data_post_fix+'.np'\n",
    "#     with open(outfile, 'rb') as pickle_file:\n",
    "#         X_test = pickle.load(pickle_file)\n",
    "\n",
    "#     outfile = 'D:/meronym_data/X_test'+obj_data_postfix+'.np'\n",
    "#     with open(outfile, 'rb') as pickle_file:\n",
    "#         X_obj_test = pickle.load(pickle_file)\n",
    "        \n",
    "        \n",
    "    return X_train, class_v, masks, X_train_val, class_v_val, masks_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98aaf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_latent(a, b, c, d=None):\n",
    "    p = np.random.permutation(len(a))\n",
    "    if d is None:\n",
    "        return a[p], b[p], c[p]\n",
    "    return a[p], b[p], c[p], d[p]\n",
    "\n",
    "def sampling(z_mean, z_log_var):\n",
    "    epsilon = tf.random_normal(tf.shape(z_log_var), name=\"epsilon\")\n",
    "    return z_mean + epsilon * tf.exp(z_log_var)\n",
    "\n",
    "\n",
    "\n",
    "def frange_cycle_linear(n_iter, start=0.0, stop=1.0,  n_cycle=4, ratio=0.5):\n",
    "    L = np.ones(n_iter) * stop\n",
    "    period = n_iter/n_cycle\n",
    "    step = (stop-start)/(period*ratio)\n",
    "\n",
    "    for c in range(n_cycle):\n",
    "        v, i = start, 0\n",
    "        while v <= stop and (int(i+c*period) < n_iter):\n",
    "            L[int(i+c*period)] = v\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86301980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(true_masks, pred_masks, z_mean, z_logvar, z_latent):\n",
    "    \n",
    "    kl_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(tf.exp(z_logvar)) - 2*(z_logvar) - 1,\n",
    "                                                 axis=1))\n",
    "    \n",
    "    mask_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(true_masks,pred_masks))\n",
    "\n",
    "    return mask_loss, kl_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c591a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_num_node = 16\n",
    "latent_dims = 64\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dims,))\n",
    "\n",
    "true_maps = keras.Input(shape=([max_num_node, 64, 64, 1]), dtype=tf.float32)\n",
    "true_masks = keras.Input(shape=([max_num_node, 64, 64, 1]), dtype=tf.float32)\n",
    "true_edges = keras.Input(shape=([max_num_node, 64, 64, 1]), dtype=tf.float32)\n",
    "\n",
    "true_bbxs = keras.Input(shape=([max_num_node, 4]), dtype=tf.float32)\n",
    "cond_bbxs = keras.Input(shape=([max_num_node, 4]), dtype=tf.int32)\n",
    "\n",
    "true_lbls = keras.Input(shape=([max_num_node, 1]), dtype=tf.float32)\n",
    "cond_lbls = keras.Input(shape=([max_num_node, 1]), dtype=tf.float32)\n",
    "\n",
    "true_classes = keras.Input(shape=([7]), dtype=tf.float32)\n",
    "cond_classes = keras.Input(shape=([7]), dtype=tf.float32)\n",
    "\n",
    "\n",
    "rnn_bbxs = layers.Bidirectional(layers.GRU(4, return_sequences=True))(true_bbxs)\n",
    "concatenated_bbx_lbl = rnn_bbxs\n",
    "dense_cond = layers.Dense(64, activation='tanh')(true_classes)\n",
    "enc = layers.TimeDistributed(layers.Conv2D(8, kernel_size=3))(true_masks)\n",
    "enc = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(enc)\n",
    "enc = layers.TimeDistributed(layers.Activation('relu'))(enc)\n",
    "\n",
    "enc = layers.TimeDistributed(layers.Conv2D(16, kernel_size=3))(enc)\n",
    "enc = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(enc)\n",
    "enc = layers.TimeDistributed(layers.Activation('relu'))(enc)\n",
    "\n",
    "enc = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(enc)\n",
    "\n",
    "enc = layers.TimeDistributed(layers.Conv2D(32, kernel_size=3, activation='relu'))(enc)\n",
    "enc = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(enc)\n",
    "enc = layers.TimeDistributed(layers.Activation('relu'))(enc)\n",
    "enc = layers.TimeDistributed(layers.Flatten())(enc)\n",
    "TDD = layers.TimeDistributed(layers.Dense(64, activation='relu', name = 'encoded_bitmaps'))\n",
    "dense_enc_maps = TDD(enc)\n",
    "\n",
    "BGRU = layers.Bidirectional(layers.GRU(32, return_sequences=True))\n",
    "rnn_maps = BGRU(dense_enc_maps)\n",
    "\n",
    "D = layers.Dense(64, activation='tanh')\n",
    "attention = D(concatenated_bbx_lbl)\n",
    "sent_representation = layers.Multiply()([rnn_maps, attention])\n",
    "sent_representation = layers.Multiply()([sent_representation, dense_cond])\n",
    "images_with_attention = layers.Lambda(lambda xin: K.sum(xin, axis=-2),\n",
    "                                            output_shape=(128,))(sent_representation)\n",
    "\n",
    "z_mean = layers.Dense(64, activation='tanh')(images_with_attention)\n",
    "z_log_var = layers.Dense(64, activation='tanh', name='z_logvar')(images_with_attention)\n",
    "\n",
    "# z_latent = z_mean #sampling(z_mean, z_log_var)\n",
    "z_latent = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=[true_bbxs, true_classes, true_masks],\n",
    "                      outputs=[z_mean, z_log_var, z_latent], \n",
    "                      name='encoder')\n",
    "\n",
    "# Decoder\n",
    "cond_bbx = layers.Lambda(lambda xin: K.sum(xin, axis=-1), output_shape=(4,))(cond_bbxs)\n",
    "cond_cat = cond_bbx\n",
    "\n",
    "cond_fully_cat = layers.Dense(64, activation='relu')(cond_cat)\n",
    "cond_class_ = layers.Dense(64, activation='relu')(cond_classes)\n",
    "conditioned_z = layers.concatenate([cond_fully_cat, latent_inputs], axis=-1, name='conditioned_z_1')\n",
    "conditioned_z = layers.concatenate([conditioned_z, cond_class_], axis=-1, name='conditioned_z_2')\n",
    "decoded = layers.RepeatVector(max_num_node)(conditioned_z)\n",
    "decoded = layers.Bidirectional(layers.GRU(32, return_sequences=True))(decoded)\n",
    "dec_dense = layers.TimeDistributed(layers.Dense(12544, activation='relu',  name = 'encoding'))(decoded)\n",
    "dec_conv = layers.TimeDistributed(layers.Reshape((28, 28, 16)))(dec_dense)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.Conv2DTranspose(16, kernel_size=3, padding='same'))(dec_conv)\n",
    "dec = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(dec)\n",
    "dec = layers.TimeDistributed(layers.Activation('relu'))(dec)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.Conv2DTranspose(8, kernel_size=3))(dec)\n",
    "dec = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(dec)\n",
    "dec = layers.TimeDistributed(layers.Activation('relu'))(dec)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.UpSampling2D(size=(2, 2)))(dec)\n",
    "\n",
    "dec = layers.TimeDistributed(layers.Conv2DTranspose(8, kernel_size=3))(dec)\n",
    "dec = layers.TimeDistributed(layers.BatchNormalization(trainable = False))(dec)\n",
    "dec = layers.TimeDistributed(layers.Activation('relu'))(dec)\n",
    "\n",
    "decoder_bitmaps = layers.TimeDistributed(layers.Conv2DTranspose(1, kernel_size=3,\n",
    "                                                                            activation='sigmoid', \n",
    "                                                                            name = 'decoded_mask'))(dec)\n",
    "decoder = keras.Model(inputs=[cond_bbxs, cond_classes, latent_inputs],\n",
    "                      outputs=decoder_bitmaps, \n",
    "                      name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c86f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 16, 64, 64,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 16, 62, 62, 8 80          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 16, 62, 62, 8 32          time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 16, 62, 62, 8 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 16, 60, 60, 1 1168        time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 16, 60, 60, 1 64          time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 16, 60, 60, 1 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 16, 30, 30, 1 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 16, 28, 28, 3 4640        time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 16, 28, 28, 3 128         time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 16, 28, 28, 3 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 16, 25088)    0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 16, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 16, 64)       1605696     time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 16, 8)        240         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 16, 64)       18816       time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16, 64)       576         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16, 64)       0           bidirectional_1[0][0]            \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           512         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16, 64)       0           multiply[0][0]                   \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 64)           0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "z_logvar (Dense)                (None, 64)           4160        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 64)           0           dense_2[0][0]                    \n",
      "                                                                 z_logvar[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,640,272\n",
      "Trainable params: 1,640,048\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6288847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.train_mask_loss = keras.metrics.Mean(name=\"train_mask_loss\")\n",
    "        self.val_mask_loss = keras.metrics.Mean(name=\"val_mask_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.kl_weight = 0\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.train_mask_loss,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def reconstruction_loss(self, true_masks, pred_masks, z_mean, z_logvar, z_latent):\n",
    "    \n",
    "        kl_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(tf.exp(z_logvar)) - 2*(z_logvar) - 1,\n",
    "                                                     axis=1))\n",
    "        mask_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(true_masks,pred_masks))\n",
    "\n",
    "        return mask_loss, kl_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        print(data)\n",
    "        (bx, cls, mask) = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z_latent = self.encoder(data)\n",
    "            pred_mask = self.decoder((bx, cls, z_latent))\n",
    "            mask_loss, kl_loss = self.reconstruction_loss(mask, pred_mask, z_mean, z_logvar, z_latent)\n",
    "            total_loss = mask_loss + kl_loss*kl_weight\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.mask_loss.update_state(mask_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        if (kl_loss > 10.0 \n",
    "            and abs(self._train_mask_loss.result() - self.val_mask_loss.result()) < 0.1 \n",
    "            and self.kl_weight<0.5):\n",
    "            self.kl_weight += 0.01 \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"mask_loss\": self.mask_loss.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def val_step(self, data):\n",
    "        z_mean, z_log_var, z_latent = self.encoder(data)\n",
    "        (bx, cls, mask) = data[0]\n",
    "        pred_mask = self.decoder((bx, cls, z_latent))\n",
    "        mask_loss, kl_loss = self.reconstruction_loss(mask, pred_mask, z_mean, z_logvar, z_latent)\n",
    "        total_loss = mask_loss + kl_loss*kl_weight\n",
    "        self.val_mask_loss.update_state(mask_loss)\n",
    "        return {\n",
    "            \"val_mask_loss\": self.total_loss_tracker.result()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a245ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "((<tf.Tensor 'IteratorGetNext:0' shape=(None, 16, 4) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 7) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 16, 64, 64, 1) dtype=float32>),)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:800 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:790 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:783 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18772\\2717656065.py:34 train_step\n        mask_loss, kl_loss = self.reconstruction_loss(true_masks, pred_masks, z_mean, z_logvar, z_latent)\n\n    NameError: name 'pred_masks' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     10\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00001/maskvae.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     12\u001b[0m )]\n\u001b[0;32m     14\u001b[0m mask_vae_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(lr))\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmask_vae_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_v_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m mask_vae_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00001/maskvae_final\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1095\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1090\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1091\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1092\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1093\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1094\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1095\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1096\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1097\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3193\u001b[0m ]\n\u001b[0;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: in user code:\n\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:800 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:790 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:783 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18772\\2717656065.py:34 train_step\n        mask_loss, kl_loss = self.reconstruction_loss(true_masks, pred_masks, z_mean, z_logvar, z_latent)\n\n    NameError: name 'pred_masks' is not defined\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "file_postfix = '_combined_mask_data'\n",
    "\n",
    "mask_vae_model = maskVAE(encoder, decoder)\n",
    "X_train, class_v, masks, X_train_val, class_v_val, masks_val = load_data(file_postfix)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train[:,:,1:], class_v, masks))\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((X_train_val[:,:,1:], class_v_val, masks_val))\n",
    "\n",
    "ckpt = [tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"D:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00001/maskvae.ckpt\",\n",
    "    save_freq=10\n",
    ")]\n",
    "\n",
    "mask_vae_model.compile(optimizer=keras.optimizers.Adam(lr))\n",
    "mask_vae_model.fit(((X_train[:,:,1:], class_v, masks)), epochs=200, batch_size=16, callbacks=ckpt, validation_data=(X_train_val[:,:,1:], class_v_val, masks_val), shuffle=True)\n",
    "mask_vae_model.save(\"D:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00001/maskvae_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e4a78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((16, 4), (7,), (16, 64, 64, 1)), types: (tf.float64, tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskVAE = keras.models.Model(inputs=[true_masks, true_bbxs, true_classes, cond_bbxs, cond_classes],\n",
    "                               outputs=[decoder_bitmaps, z_mean, z_log_var, z_latent])\n",
    "\n",
    "maskVAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec33433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.00001\n",
    "X_train, class_v, masks, X_train_val, class_v_val, masks_val = load_data(file_postfix)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, class_v, masks))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_train_val, class_v_val, masks_val))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(100).batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "labels = X_train[:,:,:1] \n",
    "bounding_boxes = X_train[:,:,1:]\n",
    "masks = masks\n",
    "classes = class_v\n",
    "\n",
    "labels_val = X_train_val[:,:,:1] \n",
    "bounding_boxes_val = X_train_val[:,:,1:]\n",
    "masks_val = masks_val\n",
    "classes_val = class_v_val\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "# maskVAE.compile(optimizer=opt)\n",
    "nb_train = masks.shape[0]\n",
    "n_epochs = 200\n",
    "klw = 0.00001\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  epoch_train_reconstruction_loss_avg = keras.metrics.Mean() # Keeping track of the training loss\n",
    "  nb_batches = nb_train // batch_size\n",
    "  start_time=time.time()\n",
    "  for step, (x_in, cls_in, mx_in) in enumerate(train_dataset):\n",
    "    labels = tf.cast(x_in[:,:,:1],dtype=tf.float32) \n",
    "    bx_in = tf.cast(x_in[:,:,1:],dtype=tf.float32)\n",
    "    cls_in = tf.cast(cls_in, dtype=tf.float32)\n",
    "    mx_in = tf.cast(mx_in, dtype=tf.float32)\n",
    "    \n",
    "    with tf.GradientTape() as tape: # Forward pass\n",
    "      pred_masks, z_mean, z_logvar, z_latent = maskVAE([mx_in, bx_in, cls_in, bx_in, cls_in],\n",
    "                                                       training=True)\n",
    "      mask_loss, kl_loss = reconstruction_loss(mx_in, pred_masks, z_mean, z_logvar, z_latent)\n",
    "      loss = mask_loss+klw*kl_loss\n",
    "      \n",
    "    grad = tape.gradient(loss, maskVAE.trainable_weights) # Backpropagation\n",
    "    opt.apply_gradients(zip(grad, maskVAE.trainable_weights)) # Update network weights\n",
    "\n",
    "    epoch_train_reconstruction_loss_avg(loss)\n",
    "    \n",
    "#   loss_train[epoch] = epoch_train_reconstruction_loss_avg.result()\n",
    "\n",
    "  for step, (x_in, cls_in, mx_in) in enumerate(val_dataset): \n",
    "    labels = tf.cast(x_in[:,:,:1],dtype=tf.float32) \n",
    "    bx_in = tf.cast(x_in[:,:,1:],dtype=tf.float32)\n",
    "    cls_in = tf.cast(cls_in, dtype=tf.float32)\n",
    "    mx_in = tf.cast(mx_in, dtype=tf.float32)\n",
    "    \n",
    "    pred_masks, z_mean, z_logvar, z_latent = maskVAE([mx_in, bx_in, cls_in, bx_in, cls_in],\n",
    "                                                     training=False) # Validation predictions\n",
    "    mask_loss_val, kl_loss_val = reconstruction_loss(mx_in, pred_masks, z_mean, z_logvar, z_latent)\n",
    "    break\n",
    "\n",
    "  print('epoch:',epoch,\n",
    "        'kl_weight', klw,\n",
    "        'kl:', kl_loss .numpy(), \n",
    "        'train:', epoch_train_reconstruction_loss_avg.result().numpy(),\n",
    "        'val:',mask_loss_val.numpy(),\n",
    "        'time:', time.time()-start_time)\n",
    "    \n",
    "  if kl_loss > 10.0 and abs(mask_loss - mask_loss_val) < 0.1 and klw<0.5:\n",
    "    klw += 0.01\n",
    "  if epoch % 10 == 0:\n",
    "    maskVAE.save(\"D:/meronym_data/runs/mask_generation_model_tf2_reconstruction/lr00001/maskvae.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a507543",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_train = keras.metrics.Mean()\n",
    "if not abs(epoch_train.result()-epoch_train.result())<0:\n",
    "    print(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
