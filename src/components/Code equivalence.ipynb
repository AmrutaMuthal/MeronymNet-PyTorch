{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942a5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras.layers import *\n",
    "import math\n",
    "from tensorflow.keras import backend as K\n",
    "import sys\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c00c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc01d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7012c8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_6960/4222297590.py:87: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Output shape of condition:  (128, 98)\n",
      "Output Shapes of Decoder- bbx_recons: (128, 24, 4), lbl_recons: (128, 24, 1), E_recons: (128, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 128\n",
    "latent_dim = 64\n",
    "label_size = 1\n",
    "bbx_size = 4 #change to 6 for oriented bbox\n",
    "class_size = 10\n",
    "lr =0.00005\n",
    "nb_epochs=300\n",
    "max_num_node = 24\n",
    "\n",
    "true_node = tf.placeholder(tf.float32, [batch_size, max_num_node, label_size + bbx_size])\n",
    "\n",
    "true_class = tf.placeholder(tf.float32 , [batch_size, max_num_node,1])\n",
    "\n",
    "true_classpred = tf.placeholder(tf.float32 , [batch_size, max_num_node,1])\n",
    "\n",
    "true_edge = tf.placeholder(tf.float32 , [batch_size, max_num_node, max_num_node])\n",
    "\n",
    "class_vec = tf.placeholder(tf.float32 , [batch_size, class_size])\n",
    "class_vecpred = tf.placeholder(tf.float32 , [batch_size, class_size])\n",
    "\n",
    "kl_weight = tf.placeholder(tf.float32)\n",
    "\n",
    "dim_vec = tf.placeholder(tf.float32 , [batch_size, 2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "area_weights =  tf.placeholder(tf.float32 , [batch_size, max_num_node,1])\n",
    "\n",
    "def init_weights(shape):\n",
    "    init = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    # x ----> [batch , height , width , channels]\n",
    "    # w ----> [filter height , filter width , channel in , channel out]\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "def max_pool_2b2(x):\n",
    "    # x ----> [batch , height , width , channels]\n",
    "    return tf.nn.max_pool(x , ksize = [1,2,2,1] , strides= [1,2,2,1],padding='SAME')\n",
    "\n",
    "def conv_layer(input_x , shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x,W) + b)\n",
    "\n",
    "def calc_num_wts():    \n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    print(\"Total number of trainable parameters:\", total_parameters)\n",
    "\n",
    "def sampling(z_mean, z_log_var):\n",
    "    epsilon = tf.random_normal(tf.shape(z_log_var), name=\"epsilon\")\n",
    "    return z_mean + epsilon * tf.exp(z_log_var)\n",
    "\n",
    "def GCLayer(E, X, out_dims):\n",
    "    W = tf.Variable(np.random.normal(0, 0.2, size=[X.shape[-1], out_dims]), dtype=tf.float32, name='W')\n",
    "    W = tf.tile(tf.expand_dims(W, axis=0), [tf.shape(X)[0], 1, 1])\n",
    "    \n",
    "    T = tf.convert_to_tensor(tf.keras.backend.sum(E, axis=-1))\n",
    "    T = tf.convert_to_tensor(tf.linalg.diag(T))\n",
    "    T = tf.matrix_inverse(T)\n",
    "\n",
    "    EX = tf.matmul(T, E)\n",
    "    EX1 = tf.matmul(EX, X)\n",
    "    EXW = tf.matmul(EX1, W)\n",
    "    X_out = tf.nn.relu(EXW)\n",
    "\n",
    "    return X_out\n",
    "\n",
    "def encoder(E, X_DATA, latent_dim, class_info):\n",
    "    X1 = GCLayer(E, X_DATA, 32)\n",
    "    X2 = GCLayer(E, X1, 16)\n",
    "    \n",
    "    BOXES =X_DATA[:,:, label_size::]\n",
    "    BOXES =tf.nn.relu(tf.layers.dense(BOXES, 16))\n",
    "    \n",
    "    LABELS =X_DATA[:,:, :label_size]\n",
    "    LABELS =tf.nn.relu(tf.layers.dense(LABELS, 16))\n",
    "\n",
    "    MIX = tf.keras.layers.Add()([BOXES, LABELS])\n",
    "\n",
    "    MIX_FLAT = tf.reshape(MIX, [-1, MIX.shape[1]*MIX.shape[2]])\n",
    "    MIX_DENSE = tf.nn.relu(tf.layers.dense(MIX_FLAT, 128))\n",
    "\n",
    "    \n",
    "    X2_f = tf.reshape(X2, [-1, X2.shape[1]*X2.shape[2]])\n",
    "    X2_f = tf.keras.layers.concatenate([class_info, X2_f], axis = -1)\n",
    "    X3 = tf.nn.relu(tf.layers.dense(X2_f, 128))\n",
    "    X4 = tf.keras.layers.Add()([MIX_DENSE, X3])\n",
    "    X5 = tf.nn.relu(tf.layers.dense(X4, 128))\n",
    "    X5 = tf.nn.relu(tf.layers.dense(X5, 128))\n",
    "        \n",
    "    z_mean = tf.nn.relu(tf.layers.dense(X5, latent_dim))\n",
    "    z_logvar = tf.nn.relu(tf.layers.dense(X5, latent_dim))\n",
    "    \n",
    "    return z_mean, z_logvar\n",
    "\n",
    "def decoder(z_latent, num_nodes):\n",
    "    x1 = tf.nn.relu(tf.layers.dense(z_latent, 128))\n",
    "    x3d = tf.nn.relu(tf.layers.dense(x1, 128))\n",
    "    x3 = tf.nn.relu(tf.layers.dense(x3d, 128))\n",
    "    \n",
    "    x_bbx = tf.nn.sigmoid(tf.layers.dense(x3, num_nodes*(bbx_size)))\n",
    "    x_bbx = tf.reshape(x_bbx, [-1, num_nodes, bbx_size])\n",
    "    \n",
    "    x_lbl = tf.nn.sigmoid(tf.layers.dense(x3, num_nodes*(label_size)))\n",
    "    x_lbl = tf.reshape(x_lbl, [-1, num_nodes, label_size])\n",
    "    \n",
    "    x_edge = tf.nn.sigmoid(tf.layers.dense(x3, num_nodes*num_nodes))\n",
    "    x_edge = tf.reshape(x_edge, [-1, num_nodes, num_nodes])\n",
    "    \n",
    "    class_ = tf.nn.softmax(tf.layers.dense(x3, class_size))\n",
    "    \n",
    "    return x_bbx, x_lbl, x_edge, class_\n",
    "\n",
    "def conditioning(condition, out_dims):\n",
    "    W = tf.Variable(np.random.normal(0, 0.2, size=[condition.shape[-1], out_dims]), dtype=tf.float32)\n",
    "    B = tf.Variable(tf.constant(0.1, shape=[out_dims]))\n",
    "    \n",
    "    W = tf.tile(tf.expand_dims(W, axis=0), [tf.shape(condition)[0], 1, 1])\n",
    "    \n",
    "    weighted_condition = tf.matmul(condition, W) + B\n",
    "    return weighted_condition\n",
    "\n",
    "def condition_z(condition):\n",
    "    weighted_condition = conditioning(condition, 32)\n",
    "    reshaped_condition = tf.reshape(weighted_condition, [-1, weighted_condition.shape[1]*weighted_condition.shape[2]])\n",
    "    return tf.nn.relu(tf.layers.dense(reshaped_condition, 64))\n",
    "\n",
    "def AutoEncodertf(E, X, latent_dimm, condition, class_condition):\n",
    "    z_mean, z_logvar = encoder(E, X, latent_dimm, class_condition)\n",
    "    z_latent = sampling(z_mean, z_logvar)\n",
    "    condition_ = tf.reshape(condition, (-1, condition.shape[1]*condition.shape[2]))\n",
    "    \n",
    "    conditioned_z = tf.keras.layers.concatenate([condition_, z_latent], axis = -1)\n",
    "    \n",
    "    conditioned_z = tf.keras.layers.concatenate([class_condition, conditioned_z], axis = -1)\n",
    "    \n",
    "    print(\"Output shape of condition: \", conditioned_z.shape)\n",
    "    node_box_r, node_cls_r, E_recons, class_ = decoder(conditioned_z, max_num_node)\n",
    "    print(\"Output Shapes of Decoder- bbx_recons: {}, lbl_recons: {}, E_recons: {}\".format(node_box_r.shape, node_cls_r.shape, E_recons.shape))\n",
    "    \n",
    "    return node_box_r, node_cls_r, E_recons, z_latent, z_mean, z_logvar,conditioned_z,class_\n",
    "\n",
    "node_box_r, node_cls_r, edge_r, z_latent, z_mean, z_logvar, conditioned_z, class_= AutoEncoder(true_edge, true_node, latent_dim,  true_class, class_vec)\n",
    "\n",
    "node_cls_t = true_node[:, :, :label_size]\n",
    "node_box_t = true_node[:, :, label_size:]\n",
    "\n",
    "def frange_cycle_linear(n_iter, start=0.0, stop=1.0,  n_cycle=4, ratio=0.5):\n",
    "    L = np.ones(n_iter) * stop\n",
    "    period = n_iter/n_cycle\n",
    "    step = (stop-start)/(period*ratio)\n",
    "\n",
    "    for c in range(n_cycle):\n",
    "        v, i = start, 0\n",
    "        while v <= stop and (int(i+c*period) < n_iter):\n",
    "            L[int(i+c*period)] = v\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L\n",
    "\n",
    "def graph_loss(A_true, A_pred):    \n",
    "    diag_elem = tf.zeros(A_pred.shape[0:-1])\n",
    "    diag_elem = tf.cast(diag_elem, tf.float32)\n",
    "    \n",
    "    true_nodes = tf.linalg.diag_part(A_true)\n",
    "    pred_nodes = tf.linalg.diag_part(A_pred)\n",
    "    \n",
    "    true_edges = tf.matrix_set_diag(A_true, diag_elem, name='true_edges')\n",
    "    pred_edges = tf.matrix_set_diag(A_pred, diag_elem, name='pred_edges')\n",
    "\n",
    "    node_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=true_nodes, logits=pred_nodes))\n",
    "    edge_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=true_edges, logits=pred_edges))\n",
    "    \n",
    "    k = A_true.shape[1]\n",
    "    k = tf.cast(k, dtype=tf.float32)\n",
    "    \n",
    "    total_loss = (node_loss / k) + (edge_loss / (k*(k-1)))\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def upper_triangle(mat):\n",
    "    t = tf.matrix_band_part(mat, 0, -1)\n",
    "    diag_elem = tf.zeros(t.shape[0:-1])\n",
    "    diag_elem = tf.cast(diag_elem, tf.float32)\n",
    "    ut_mat = tf.matrix_set_diag(t, diag_elem, name='ut_mat')\n",
    "    return ut_mat\n",
    "\n",
    "def graph_loss_ut(A_true, A_pred):\n",
    "    A_true_ut = upper_triangle(A_true)\n",
    "    A_pred_ut = upper_triangle(A_pred)\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=A_true_ut, logits=A_pred_ut))\n",
    "    k = A_true.shape[1]\n",
    "    k = tf.cast(k, dtype=tf.float32)\n",
    "    nb_edges = k*k/2 - k\n",
    "    loss = loss / (nb_edges)\n",
    "    return loss\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "  \"\"\"Implements Smooth-L1 loss.\n",
    "  y_true and y_pred are typically: [N, 4], but could be any shape.\n",
    "  \"\"\"\n",
    "  diff = K.abs(y_true - y_pred)\n",
    "  less_than_one = K.cast(K.less(diff, 0.01), \"float32\")\n",
    "  loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.005)\n",
    "  return loss\n",
    "\n",
    "def box_loss(tru_box, gen_box):\n",
    "    gen_box = ((gen_box)*(tru_box != 0))\n",
    "    tru_box = ((tru_box)*(tru_box != 0))\n",
    "    sum_r = tf.dtypes.cast(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box)), tf.float32)\n",
    "    num_r = tf.dtypes.cast(tf.math.count_nonzero(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box), axis=-1)), tf.float32)\n",
    "    return (sum_r/(num_r+1))\n",
    "\n",
    "def box_loss_wt(tru_box, gen_box,area_weights):\n",
    "    gen_box = ((gen_box)*(tru_box != 0))\n",
    "    tru_box = ((tru_box)*(tru_box != 0))\n",
    "    sum_r = tf.dtypes.cast(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box)**tf.squeeze(area_weights)), tf.float32)\n",
    "    num_r = tf.dtypes.cast(tf.math.count_nonzero(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box), axis=-1)), tf.float32)\n",
    "    return (sum_r/(num_r+1))\n",
    "\n",
    "def area(boxlist):\n",
    "    x_min, y_min, x_max, y_max = tf.split(\n",
    "        value=boxlist, num_or_size_splits=4, axis=-1)\n",
    "    return (y_max - y_min+ 1e-10) * (x_max - x_min + 1e-10)\n",
    "\n",
    "def aspect_ratio(boxlist):\n",
    "    x_min, y_min, x_max, y_max = tf.split(\n",
    "        value=boxlist, num_or_size_splits=4, axis=-1)\n",
    "    return (y_max - y_min + 1e-10 ) / (x_max - x_min + 1e-10)\n",
    "\n",
    "def iou(target,  output):\n",
    "\n",
    "    output = ((output)*(target != 0))\n",
    "    target = ((target)*(target != 0))\n",
    "\n",
    "    x1g, y1g, x2g, y2g = tf.split(value=target, num_or_size_splits=4, axis=-1)\n",
    "    x1, y1, x2, y2 = tf.split(value=output, num_or_size_splits=4, axis=-1)\n",
    "    \n",
    "    ###iou###\n",
    "    xA = tf.maximum(x1g, x1)\n",
    "    yA = tf.maximum(y1g, y1)\n",
    "    xB = tf.minimum(x2g, x2)\n",
    "    yB = tf.minimum(y2g, y2)\n",
    "    \n",
    "    interArea = tf.maximum(0.0, (xB - xA + 1)) * tf.maximum(0.0, yB - yA + 1)\n",
    "    boxAArea = (x2g - x1g +1) * (y2g - y1g +1)\n",
    "    boxBArea = (x2 - x1 +1) * (y2 - y1 +1)\n",
    "    iouk = interArea / (boxAArea + boxBArea - interArea)\n",
    "    \n",
    "    return iouk\n",
    "\n",
    "def iou_obb(target,  output):\n",
    "\n",
    "    output = ((output)*(target != 0))\n",
    "    target = ((target)*(target != 0))\n",
    "\n",
    "    x1g, y1g, x2g, y2g,dg = tf.split(value=target, num_or_size_splits=5, axis=-1)\n",
    "    x1, y1, x2, y2,d = tf.split(value=output, num_or_size_splits=5, axis=-1)\n",
    "    ###iou###\n",
    "    xA = tf.maximum(x1g, x1)\n",
    "    yA = tf.maximum(y1g, y1)\n",
    "    xB = tf.minimum(x2g, x2)\n",
    "    yB = tf.minimum(y2g, y2)\n",
    "    interArea = tf.maximum(0.0, (xB - xA + 1)) * tf.maximum(0.0, yB - yA + 1)\n",
    "    boxAArea = (x2g - x1g +1) * (y2g - y1g +1)\n",
    "    boxBArea = (x2 - x1 +1) * (y2 - y1 +1)\n",
    "    iouk = interArea / (boxAArea + boxBArea - interArea)\n",
    "    \n",
    "    return iouk\n",
    "\n",
    "def pair_loss(target,  output):\n",
    "\n",
    "    output = ((output)*(target != 0))\n",
    "    target = ((target)*(target != 0))\n",
    "\n",
    "    output_unstacked = tf.unstack(output,num=None,axis=-2)\n",
    "    target_unstacked = tf.unstack(target,num=None,axis=-2)\n",
    "\n",
    "    pairwise_iou_output = []\n",
    "    pairwise_iou_target = []\n",
    "    \n",
    "    for ii in range(len(target_unstacked)):\n",
    "        jj = ii\n",
    "        while jj<(len(target_unstacked)):\n",
    "            pairwise_iou_output.append((tf.keras.losses.MSE(output_unstacked[ii] , output_unstacked[jj])))\n",
    "            pairwise_iou_target.append((tf.keras.losses.MSE(target_unstacked[ii] , target_unstacked[jj])))\n",
    "            jj = jj + 1\n",
    "\n",
    "    pairwise_iou_output = tf.convert_to_tensor(pairwise_iou_output,dtype=tf.float32)\n",
    "    pairwise_iou_target = tf.convert_to_tensor(pairwise_iou_target,dtype=tf.float32)\n",
    "    all_loss_sum = tf.reduce_sum(tf.keras.losses.MSE(pairwise_iou_target, pairwise_iou_output))\n",
    "    total_non_zero = tf.dtypes.cast(tf.math.count_nonzero(tf.reduce_sum(tf.keras.losses.MSE(pairwise_iou_target, pairwise_iou_output),  axis = -1)),  dtype=tf.float32)\n",
    "    return all_loss_sum/(total_non_zero+1)\n",
    "\n",
    "def pair_loss_wt(target,  output,area_weights):\n",
    "\n",
    "    output = ((output)*(target != 0))\n",
    "    target = ((target)*(target != 0))\n",
    "    \n",
    "    output_unstacked = tf.unstack(output,num=None,axis=-2)\n",
    "    target_unstacked = tf.unstack(target,num=None,axis=-2)\n",
    "    area_weights_unstacked = tf.unstack(area_weights,num=None,axis=-2)\n",
    "    pairwise_iou_output = []\n",
    "    pairwise_iou_target = []\n",
    "    for ii in range(len(target_unstacked)):\n",
    "        jj = ii\n",
    "        while jj<(len(target_unstacked)):\n",
    "            pairwise_iou_output.append((tf.keras.losses.MSE(output_unstacked[ii] ,\n",
    "                                                            output_unstacked[jj]))*area_weights_unstacked[ii])\n",
    "            pairwise_iou_target.append((tf.keras.losses.MSE(target_unstacked[ii] , \n",
    "                                                            target_unstacked[jj]))*area_weights_unstacked[ii])\n",
    "            jj = jj + 1\n",
    "\n",
    "    pairwise_iou_output = tf.convert_to_tensor(pairwise_iou_output,dtype=tf.float32)\n",
    "    pairwise_iou_target = tf.convert_to_tensor(pairwise_iou_target,dtype=tf.float32)\n",
    "    all_loss_sum = tf.reduce_sum(tf.keras.losses.MSE(pairwise_iou_target, pairwise_iou_output))\n",
    "    total_non_zero = tf.dtypes.cast(tf.math.count_nonzero(tf.reduce_sum(tf.keras.losses.MSE(pairwise_iou_target, pairwise_iou_output),  axis = -1)),  dtype=tf.float32)\n",
    "    return all_loss_sum/(total_non_zero+1)\n",
    "\n",
    "def compute_ciou(target,  output):\n",
    "\n",
    "    output = ((output)*(target != 0))\n",
    "    target = ((target)*(target != 0))\n",
    "\n",
    "    x1g, y1g, x2g, y2g = tf.split(value=target, num_or_size_splits=4, axis=-1)\n",
    "    x1, y1, x2, y2 = tf.split(value=output, num_or_size_splits=4, axis=-1)\n",
    "    \n",
    "    w_pred = x2 - x1\n",
    "    h_pred = y2 - y1\n",
    "    w_gt = x2g - x1g\n",
    "    h_gt = y2g - y1g\n",
    "\n",
    "    x_center = (x2 + x1) / 2\n",
    "    y_center = (y2 + y1) / 2\n",
    "    x_center_g = (x1g + x2g) / 2\n",
    "    y_center_g = (y1g + y2g) / 2\n",
    "\n",
    "    xc1 = tf.minimum(x1, x1g)\n",
    "    yc1 = tf.minimum(y1, y1g)\n",
    "    xc2 = tf.maximum(x2, x2g)\n",
    "    yc2 = tf.maximum(y2, y2g)\n",
    "    \n",
    "    ###iou###\n",
    "    xA = tf.maximum(x1g, x1)\n",
    "    yA = tf.maximum(y1g, y1)\n",
    "    xB = tf.minimum(x2g, x2)\n",
    "    yB = tf.minimum(y2g, y2)\n",
    "    interArea = tf.maximum(0.0, (xB - xA + 1)) * tf.maximum(0.0, yB - yA + 1)\n",
    "    boxAArea = (x2g - x1g +1) * (y2g - y1g +1)\n",
    "    boxBArea = (x2 - x1 +1) * (y2 - y1 +1)\n",
    "    iouk = interArea / (boxAArea + boxBArea - interArea)\n",
    "    ciouk = -tf.log(iouk)\n",
    "    return tf.reduce_mean(ciouk)\n",
    "\n",
    "    \n",
    "def compute_ciou_wt(target,  output,area_weights):\n",
    "\n",
    "    output = ((output)*(target != 0))\n",
    "    target = ((target)*(target != 0))\n",
    "\n",
    "    x1g, y1g, x2g, y2g = tf.split(value=target, num_or_size_splits=4, axis=-1)\n",
    "    x1, y1, x2, y2 = tf.split(value=output, num_or_size_splits=4, axis=-1)\n",
    "    \n",
    "    w_pred = x2 - x1\n",
    "    h_pred = y2 - y1\n",
    "    w_gt = x2g - x1g\n",
    "    h_gt = y2g - y1g\n",
    "\n",
    "    x_center = (x2 + x1) / 2\n",
    "    y_center = (y2 + y1) / 2\n",
    "    x_center_g = (x1g + x2g) / 2\n",
    "    y_center_g = (y1g + y2g) / 2\n",
    "\n",
    "    xc1 = tf.minimum(x1, x1g)\n",
    "    yc1 = tf.minimum(y1, y1g)\n",
    "    xc2 = tf.maximum(x2, x2g)\n",
    "    yc2 = tf.maximum(y2, y2g)\n",
    "    \n",
    "    ###iou###\n",
    "    xA = tf.maximum(x1g, x1)\n",
    "    yA = tf.maximum(y1g, y1)\n",
    "    xB = tf.minimum(x2g, x2)\n",
    "    yB = tf.minimum(y2g, y2)\n",
    "    interArea = tf.maximum(0.0, (xB - xA + 1)) * tf.maximum(0.0, yB - yA + 1)\n",
    "    boxAArea = (x2g - x1g +1) * (y2g - y1g +1)\n",
    "    boxBArea = (x2 - x1 +1) * (y2 - y1 +1)\n",
    "    iouk = interArea / (boxAArea + boxBArea - interArea)\n",
    "    ciouk = -tf.log(iouk)*area_weights\n",
    "    return tf.reduce_mean(ciouk)\n",
    "\n",
    "\n",
    "kl_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(tf.exp(z_logvar)) - 2*(z_logvar) - 1, axis=1))\n",
    "adj_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(true_edge, edge_r))\n",
    "bbox_loss = (compute_ciou(node_box_t, node_box_r)) + box_loss(node_box_t, node_box_r) + pair_loss(node_box_t, node_box_r)\n",
    "\n",
    "cls_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(node_cls_t,node_cls_r))\n",
    "class_vvv = tf.reduce_mean(tf.keras.backend.categorical_crossentropy(class_vec, class_))\n",
    "\n",
    "\n",
    "reconstuction_loss = (bbox_loss + cls_loss + adj_loss + class_vvv)*24*5 + kl_weight*kl_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd56e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'D:/meronym_data/X_train_val.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_train_val = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/class_v_val.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    class_v_val = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/adj_train_val.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    adj_train_val = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1ec2d87e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer add_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Output shape of condition:  (1, 98)\n",
      "Output Shapes of Decoder- bbx_recons: (1, 24, 4), lbl_recons: (1, 24, 1), E_recons: (1, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "def AutoEncodertf(E, X, latent_dimm, condition, class_condition):\n",
    "    z_mean, z_logvar = encoder(E, X, latent_dimm, class_condition)\n",
    "    z_latent = sampling(z_mean, z_logvar)\n",
    "    condition_ = tf.reshape(condition, (-1, condition.shape[1]*condition.shape[2]))\n",
    "    \n",
    "    conditioned_z = tf.keras.layers.concatenate([condition_, z_latent], axis = -1)\n",
    "    \n",
    "    conditioned_z = tf.keras.layers.concatenate([class_condition, conditioned_z], axis = -1)\n",
    "    \n",
    "    print(\"Output shape of condition: \", conditioned_z.shape)\n",
    "    node_box_r, node_cls_r, E_recons, class_ = decoder(conditioned_z, max_num_node)\n",
    "    print(\"Output Shapes of Decoder- bbx_recons: {}, lbl_recons: {}, E_recons: {}\".format(node_box_r.shape, node_cls_r.shape, E_recons.shape))\n",
    "    \n",
    "    return node_box_r, node_cls_r, E_recons, z_latent, z_mean, z_logvar,conditioned_z,class_\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.random.set_random_seed(100)\n",
    "    embed = AutoEncodertf(adj_train_val[:1],X_train_val[:1],64, X_train_val[:1,:,:1],class_v_val[:1])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    embedding = sess.run(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4728a780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_box_r, node_cls_r, E_recons, z_latent, z_mean, z_logvar,conditioned_z,class_ = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "53c5c5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14521512"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(pair_loss(X_train_val[:1,:,1:].astype('float32'),node_box_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b46e6ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037283994"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(pair_loss(X_train_val[:1,:,1:].astype('float32'),node_data_pred.detach().cpu().numpy().astype('float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9dab34bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69942504"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.reduce_mean(tf.keras.backend.binary_crossentropy(adj_train_val[:1], E_recons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4f8b5e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5386, device='cuda:0')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.kl_loss(torch.from_numpy(z_mean).cuda(),torch.from_numpy(z_logvar).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "53be6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "72c47655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5386)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.kl_loss(torch.from_numpy(z_mean), torch.from_numpy(z_logvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0e24c0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.69942522, device='cuda:0')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.adj_loss(torch.from_numpy(E_recons).cuda(),adj_true,batch,num_nodes=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "37b0f67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0296247 , 0.00390405, 0.        , 0.00771168, 0.        ,\n",
       "        0.01131818, 0.        , 0.        , 0.01071849, 0.00561339,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "gen_box = node_box_r#node_data_pred.detach().cpu().numpy().astype('float32')\n",
    "tru_box = X_train_val[:1,:,1:].astype('float32')\n",
    "gen_box = ((gen_box)*(tru_box != 0))\n",
    "tru_box = ((tru_box)*(tru_box != 0))\n",
    "sum_r = tf.dtypes.cast(tf.keras.losses.MSE(tru_box, gen_box), tf.float32)\n",
    "num_r = tf.dtypes.cast(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box), axis=-1), tf.float32)\n",
    "loss = sum_r/(num_r+1)\n",
    "sess.run(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "03390bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0565, device='cuda:0', dtype=torch.float64),\n",
       " tensor(0.0170, device='cuda:0', dtype=torch.float64),\n",
       " tensor(0.1452, device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_loss(torch.from_numpy(node_box_r).cuda(),torch.from_numpy(X_train_val[:1,:,1:]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c3547851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0555, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0189, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " tensor(0.0373, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_loss(node_data_pred,torch.from_numpy(X_train_val[:1,:,1:]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a2eefe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_loss(tru_box, gen_box):\n",
    "    gen_box = ((gen_box)*(tru_box != 0))\n",
    "    tru_box = ((tru_box)*(tru_box != 0))\n",
    "    sum_r = tf.dtypes.cast(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box)), tf.float32)\n",
    "    num_r = tf.dtypes.cast(tf.math.count_nonzero(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box), axis=-1)), tf.float32)\n",
    "    \n",
    "    return sum_r/(num_r+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29459b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoder import Encoder\n",
    "from AutoEncoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e479b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse, to_dense_adj\n",
    "import losses\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11985fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f17492f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "val_list = []\n",
    "for idx, batch in enumerate(zip(X_train_val[:1],\n",
    "                                class_v_val[:1], \n",
    "                                adj_train_val[:1])):\n",
    "    edge_index, _ = dense_to_sparse(torch.from_numpy(batch[2]).float())\n",
    "    val_list.append(Data(x = torch.from_numpy(batch[0]).float(),\n",
    "                         y = torch.from_numpy(batch[1]).float(),\n",
    "                         edge_index = edge_index\n",
    "                                )\n",
    "                     )\n",
    "batch_val_loader = DataLoader(val_list, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4820fff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\Workspace\\MeronymNet-PyTorch\\src\\components\\Decoder.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  class_pred = self.act2(self.dense_cls(x))\n"
     ]
    }
   ],
   "source": [
    "latent_dims = 64\n",
    "batch_size = 64\n",
    "num_nodes = 24\n",
    "bbx_size = 4\n",
    "num_classes = 10\n",
    "label_shape = 1\n",
    "nb_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "hidden1 = 32\n",
    "hidden2 = 16\n",
    "hidden3 = 128\n",
    "vae = AutoEncoder(latent_dims,num_nodes,bbx_size,num_classes,label_shape,hidden1, hidden2, hidden3)\n",
    "vae.cuda()\n",
    "for val_data in batch_val_loader:\n",
    "    val_data.cuda()\n",
    "    node_data_true = val_data.x\n",
    "    label_true = node_data_true[:,:1]\n",
    "    class_true = val_data.y\n",
    "    adj_true = val_data.edge_index\n",
    "    batch = val_data.batch\n",
    "\n",
    "\n",
    "    output = vae(adj_true, node_data_true, label_true , class_true)\n",
    "    node_data_pred, label_pred, adj_pred, class_pred, z_mean, z_logvar = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "048ee62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4468577 , 0.32522985], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "gen_box = node_data_pred.detach().cpu().numpy().astype('float32')\n",
    "tru_box = X_train_val[:2,:,1:].astype('float32')\n",
    "gen_box = ((gen_box)*(tru_box != 0))\n",
    "tru_box = ((tru_box)*(tru_box != 0))\n",
    "sum_r = tf.dtypes.cast(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box)), tf.float32)\n",
    "num_r = tf.dtypes.cast(tf.reduce_sum(tf.keras.losses.MSE(tru_box, gen_box), axis=-1), tf.float32)\n",
    "loss = sum_r/(num_r+1)\n",
    "sess.run(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca8fe376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 24, 4])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b87513b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14010613"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "gen_box = node_data_pred.detach().cpu().numpy().astype('float32')\n",
    "true_box = X_train_val[:2,:,1:].astype('float32')\n",
    "sess.run(compute_ciou(true_box,gen_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db28634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.799999999999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.4+2.8+1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2261895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "974336ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 24, 1])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.1544, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_loss(node_data_pred, node_data_true[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ef761b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_loss(pred_box, true_box):\n",
    "    \n",
    "    # IOU loss\n",
    "    true_box = torch.reshape(true_box,pred_box.shape)\n",
    "    mask = torch.where(torch.sum(true_box,dim=-1,keepdim=True)!=0,1.0,0.0)\n",
    "    pred_box = mask*pred_box\n",
    "    x1g, y1g, x2g, y2g = torch.tensor_split(true_box, 4, dim=-1)\n",
    "    x1, y1, x2, y2 = torch.tensor_split(pred_box, 4, dim=-1)\n",
    "    \n",
    "    xA = torch.maximum(x1g, x1)\n",
    "    yA = torch.maximum(y1g, y1)\n",
    "    xB = torch.minimum(x2g, x2)\n",
    "    yB = torch.minimum(y2g, y2)\n",
    "    \n",
    "    interArea = torch.maximum(torch.tensor([0.0]).cuda(),\n",
    "                              (xB - xA + 1)) * torch.maximum(torch.tensor([0.0]).cuda(),\n",
    "                                                         yB - yA + 1)\n",
    "    boxAArea = (x2g - x1g + 1) * (y2g - y1g + 1)\n",
    "    boxBArea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    iouk = (interArea) / (boxAArea + boxBArea - interArea + 1e-06)\n",
    "    iou_loss = -torch.log(iouk + 1e-6)\n",
    "    iou_loss = torch.mean(iou_loss)#/torch.sum(mask)\n",
    "    \n",
    "    # Box regression loss\n",
    "    reg_loss = F.mse_loss(pred_box, true_box, reduction='none')\n",
    "    reg_loss = torch.mean(reg_loss,dim = -1)\n",
    "    reg_loss = torch.sum(reg_loss,dim = -1)\n",
    "    total_non_zero = torch.count_nonzero(reg_loss)\n",
    "    reg_loss = torch.sum(reg_loss)/(total_non_zero+1)\n",
    "    \n",
    "    # Pairwise box regression loss\n",
    "    pair_mse_true = []\n",
    "    pair_mse_pred = []\n",
    "    true_unstacked = torch.unbind(true_box,dim=-2)\n",
    "    pred_unstacked = torch.unbind(pred_box,dim=-2)\n",
    "    \n",
    "    for i in range(len(true_unstacked)):\n",
    "        \n",
    "        for j in range(i, len(true_unstacked)):\n",
    "            pair_mse_true.append(F.mse_loss(true_unstacked[i],true_unstacked[j]))\n",
    "            pair_mse_pred.append(F.mse_loss(pred_unstacked[i],pred_unstacked[j]))\n",
    "        \n",
    "    \n",
    "    pair_loss = F.mse_loss(torch.stack(pair_mse_pred), \n",
    "                           torch.stack(pair_mse_true),\n",
    "                           reduction='none',\n",
    "                           )\n",
    "    total_non_zero = torch.count_nonzero(torch.sum(pair_loss,dim=-1))\n",
    "    pair_loss = torch.sum(pair_loss)/(total_non_zero+1)\n",
    "    \n",
    "    return iou_loss , reg_loss , pair_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
