{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21434d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04848158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, dense_to_sparse\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e5f3322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCLayer, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = nn.Sequential(nn.Linear(2 * in_channels, out_channels),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        edge_index,_ = dense_to_sparse(adj)\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bed22a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\" Encoder module for AutoEncoder in BoxGCN-VAE. \n",
    "    Args:\n",
    "        num_nodes: number of nodes in the encoder.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 latent_dims,\n",
    "                 num_nodes,\n",
    "                 data_size,\n",
    "                 ):\n",
    "        super(Encoder, self).__init__()\n",
    "       \n",
    "        # Encoder. Add GC layer\n",
    "        self.gconv1 = GCLayer(data_size,32)\n",
    "        self.gconv2 = GCLayer(32,16)\n",
    "        self.dense_boxes = nn.Linear(4, 16)\n",
    "        self.dense_labels = nn.Linear(1,16)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dense1 = nn.Linear(16*num_nodes,128)\n",
    "        self.dense2 = nn.Linear(17*num_nodes,128)\n",
    "        self.dense3 = nn.Linear(128,128)\n",
    "        \n",
    "        self.latent = nn.Linear(128,latent_dims)\n",
    "\n",
    "    def forward(self, E, X_data,class_labels):\n",
    "        \n",
    "        x = self.gconv1(X_data,E)\n",
    "        x = self.gconv2(x,E)\n",
    "        x = torch.flatten(x)\n",
    "        \n",
    "        boxes = X_data[:,1:]\n",
    "        boxes = self.act(self.dense_boxes(boxes))\n",
    "        \n",
    "        labels = X_data[:,:1]\n",
    "        labels = self.act(self.dense_labels(labels))\n",
    "        \n",
    "        mix = torch.add(boxes,labels)\n",
    "        mix = torch.flatten(mix)\n",
    "        mix = self.act(self.dense1(mix))\n",
    "        \n",
    "        x = torch.cat([class_labels,x])\n",
    "        x = self.act(self.dense2(x))\n",
    "        x = torch.add(x,mix)\n",
    "        x = self.act(self.dense3(x))\n",
    "        x = self.act(self.dense3(x))\n",
    "        print(x.size())\n",
    "        \n",
    "        z_mean = self.act(self.latent(x))\n",
    "        z_logvar = self.act(self.latent(x))\n",
    "        \n",
    "        return z_mean,z_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5227c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\" Decoder module for Box-Vae\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 latent_dims,\n",
    "                 num_nodes,\n",
    "                 bbx_size,\n",
    "                 class_size,\n",
    "                 label_size=1\n",
    "                 ):\n",
    "        super(Decoder, self).__init__()\n",
    "       \n",
    "        self.num_nodes = num_nodes\n",
    "        self.bbx_size = bbx_size\n",
    "        self.class_size = class_size\n",
    "        self.label_size = label_size\n",
    "        self.dense1 = nn.Linear(latent_dims,128)  \n",
    "        self.dense2 = nn.Linear(128,128)\n",
    "        self.dense_bbx = nn.Linear(128,num_nodes*bbx_size)\n",
    "        self.dense_lbl = nn.Linear(128,num_nodes*label_size)\n",
    "        self.dense_edge = nn.Linear(128,num_nodes*num_nodes)\n",
    "        self.dense_cls = nn.Linear(128,class_size)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.act2 = nn.Softmax()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        x = self.act1(self.dense1(embedding))\n",
    "        x = self.act1(self.dense2(x))\n",
    "        x = self.act1(self.dense2(x))\n",
    "        \n",
    "        x_bbx = self.act1(self.dense_bbx(x))\n",
    "        x_bbx = torch.reshape(x_bbx,[self.num_nodes,self.bbx_size])\n",
    "        \n",
    "        x_lbl = self.act1(self.dense_lbl(x))\n",
    "        x_lbl = torch.reshape(x_lbl,[self.num_nodes,self.label_size])\n",
    "        \n",
    "        x_edge = self.act1(self.dense_edge(x))\n",
    "        x_edge = torch.reshape(x_bbx,[self.num_nodes,self.num_nodes])\n",
    "        \n",
    "        class_pred = self.act2(self.dense_cls(x))\n",
    "              \n",
    "        return x_bbx, x_lbl, x_edge, class_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "df09d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    \"\"\" AutoEncoder module for Box-Vae\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 latent_dims,\n",
    "                 num_nodes,\n",
    "                 bbx_size,\n",
    "                 num_obj_classes,\n",
    "                 label_size=1\n",
    "                ):\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.latent_dims = latent_dims\n",
    "        self.num_nodes = num_nodes\n",
    "        self.encoder = Encoder(latent_dims,\n",
    "                               num_nodes,\n",
    "                               bbx_size)\n",
    "        \n",
    "        self.decoder = Decoder(latent_dims,\n",
    "                               num_nodes,\n",
    "                               bbx_size,\n",
    "                               num_obj_classes,\n",
    "                               label_size)\n",
    "        \n",
    "    def forward(self,E, X , nodes, obj_class):\n",
    "\n",
    "        z_mean, z_logvar = self.encoder(E, X, obj_class)\n",
    "        z_latent = z_mean + torch.randn(self.latent_dims)*torch.exp(z_logvar)\n",
    "        x_bbx, x_lbl, x_edge, class_pred = self.decoder(z_latent)\n",
    "        #true_edge=E, true_node=X, latent_dim,  true_class=nodes, class_vec=class_pred)\n",
    "        # conditioning has to be added\n",
    "        return x_bbx, x_lbl, x_edge, class_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b828f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(10,5,5)\n",
    "adj = torch.tensor([[1,0,0,0,1],\n",
    "                 [0,1,1,0,0],\n",
    "                 [0,1,1,1,0],\n",
    "                 [0,0,1,1,0],\n",
    "                 [1,0,1,0,1]])\n",
    "\n",
    "data = torch.FloatTensor(np.random.randint(0,100,(5,5))/100)\n",
    "class_labels = torch.tensor([1,1,1,1,1])\n",
    "z_mean, z_logvar = enc(adj,data,class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "55ddbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-2aab59780fb2>:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  class_pred = self.act2(self.dense_cls(x))\n"
     ]
    }
   ],
   "source": [
    "dec = Decoder(10,5,5,5,1)\n",
    "x_bbx, x_lbl, x_edge, class_pred = dec(z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9cd8d4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-2aab59780fb2>:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  class_pred = self.act2(self.dense_cls(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5498, 0.4814, 0.4957, 0.4198, 0.5253],\n",
       "         [0.4671, 0.3859, 0.6136, 0.4118, 0.6067],\n",
       "         [0.3947, 0.4343, 0.4350, 0.3817, 0.5505],\n",
       "         [0.5631, 0.4041, 0.3958, 0.3992, 0.5827],\n",
       "         [0.4714, 0.5076, 0.3885, 0.4637, 0.4431]], grad_fn=<ViewBackward>),\n",
       " tensor([[0.4062],\n",
       "         [0.4861],\n",
       "         [0.5251],\n",
       "         [0.5621],\n",
       "         [0.5086]], grad_fn=<ViewBackward>),\n",
       " tensor([[0.5498, 0.4814, 0.4957, 0.4198, 0.5253],\n",
       "         [0.4671, 0.3859, 0.6136, 0.4118, 0.6067],\n",
       "         [0.3947, 0.4343, 0.4350, 0.3817, 0.5505],\n",
       "         [0.5631, 0.4041, 0.3958, 0.3992, 0.5827],\n",
       "         [0.4714, 0.5076, 0.3885, 0.4637, 0.4431]], grad_fn=<ViewBackward>),\n",
       " tensor([0.1267, 0.1716, 0.3279, 0.1830, 0.1909], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = AutoEncoder(10,5,5,5,1)\n",
    "obj_class = torch.tensor([1,0,0,0,0])\n",
    "vae(adj,data,class_labels,obj_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "859afcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[4, 2], y=[4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)\n",
    "edge_index = torch.tensor([[0,1,2,3],\n",
    "                           [1,2,3,0]], \n",
    "                          dtype=torch.long)\n",
    "data = Data(x=x, y=y, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5409866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6600, 0.0100, 0.0900, 0.2400, 0.8900],\n",
       "        [0.6600, 0.0100, 0.3900, 0.2100, 0.8700],\n",
       "        [0.4000, 0.5400, 0.2100, 0.6400, 0.3600],\n",
       "        [0.8900, 0.3900, 0.7400, 0.7500, 0.2900],\n",
       "        [0.5400, 0.6400, 0.4700, 0.8900, 0.5100]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = torch.tensor([[1,0,0,0,1],\n",
    "                 [0,1,1,0,0],\n",
    "                 [0,1,1,1,0],\n",
    "                 [0,0,1,1,0],\n",
    "                 [1,0,1,0,1]])\n",
    "edge_index,_ = dense_to_sparse(adj)\n",
    "data = torch.FloatTensor(np.random.randint(0,100,(5,5))/100)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcd6eb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4],\n",
       "         [0, 4, 1, 2, 1, 2, 3, 2, 3, 0, 2, 4]]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ab7624d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0831, 0.0000, 0.0000, 0.0538, 0.0000],\n",
       "        [0.1434, 0.0000, 0.0000, 0.0530, 0.0000],\n",
       "        [0.1565, 0.0000, 0.0000, 0.1168, 0.0000],\n",
       "        [0.1176, 0.0003, 0.0000, 0.0318, 0.0000],\n",
       "        [0.1699, 0.0000, 0.0000, 0.0572, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcl1 = GCLayer(5,32)\n",
    "gcl1#(data,adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
