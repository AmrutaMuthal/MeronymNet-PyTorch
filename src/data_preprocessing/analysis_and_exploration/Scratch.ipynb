{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85be8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4c4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_data_postfix = '_obj_boundary'\n",
    "part_data_post_fix = '_scaled'\n",
    "file_postfix = '_combined'\n",
    "\n",
    "outfile = 'D:/meronym_data/X_train'+part_data_post_fix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/X_train'+obj_data_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_obj_train = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/class_v'+file_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    class_v = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/adj_train'+file_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    adj_train = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/X_train_val'+part_data_post_fix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_train_val = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/X_train_val'+obj_data_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_obj_train_val = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/class_v_val'+file_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    class_v_val = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/adj_train_val'+file_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    adj_train_val = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/X_test'+part_data_post_fix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_test = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/X_test'+obj_data_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    X_obj_test = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/adj_test'+file_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    adj_test = pickle.load(pickle_file)\n",
    "\n",
    "outfile = 'D:/meronym_data/class_v'+file_postfix+'.np'\n",
    "with open(outfile, 'rb') as pickle_file:\n",
    "    class_v_test = pickle.load(pickle_file)\n",
    "\n",
    "X_train[X_train<=0] = 0\n",
    "X_train_val[X_train_val<=0] = 0\n",
    "X_test[X_test<=0] = 0\n",
    "\n",
    "X_train[X_train>=1] = 1\n",
    "X_train_val[X_train_val>=1] = 1\n",
    "X_test[X_test>=1] = 1\n",
    "\n",
    "X_obj_train[X_obj_train<=0] = 0\n",
    "X_obj_train_val[X_obj_train_val<=0] = 0\n",
    "X_obj_test[X_obj_test<=0] = 0\n",
    "\n",
    "X_obj_train[X_obj_train>=1] = 1\n",
    "X_obj_train_val[X_obj_train_val>=1] = 1\n",
    "X_obj_test[X_obj_test>=1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff73834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50910, 16, 5)\n",
      "(50910, 4)\n",
      "(50910, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_obj_train.shape)\n",
    "print(adj_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93c282f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50910, 1, 5), (50910, 16, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.pad(X_obj_train, ((0, 0), (1, 0)), 'constant', constant_values=(1))\n",
    "temp = np.expand_dims(temp, 1)\n",
    "X_train = np.concatenate([temp, X_train], axis=1)\n",
    "adj_train = np.pad(adj_train, ((0,0), (1,0), (1,0)), 'maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53b44d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b98d022a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3299a29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 0.43939394, 0.45454545, 0.56060606, 0.54393939]]),\n",
       " array([[1.        , 0.6875    , 0.        , 1.        , 0.15254237],\n",
       "        [1.        , 0.15      , 0.06779661, 0.7625    , 0.74576271],\n",
       "        [1.        , 0.6       , 0.05084746, 0.7625    , 0.49152542],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.0625    , 0.76271186, 0.3       , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.4       , 0.71186441, 0.4625    , 0.96610169],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.55932203, 0.1625    , 0.74576271],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]),\n",
       " array([[1.        , 0.43939394, 0.45454545, 0.56060606, 0.54393939],\n",
       "        [1.        , 0.6875    , 0.        , 1.        , 0.15254237],\n",
       "        [1.        , 0.15      , 0.06779661, 0.7625    , 0.74576271],\n",
       "        [1.        , 0.6       , 0.05084746, 0.7625    , 0.49152542],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.0625    , 0.76271186, 0.3       , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.4       , 0.71186441, 0.4625    , 0.96610169],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.55932203, 0.1625    , 0.74576271],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0], X_train[0], temp2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14763051",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "train_idx = np.random.randint(1,len(X_train),len(X_train))\n",
    "val_idx = np.random.randint(1,len(X_train_val),len(X_train_val))\n",
    "test_idx = np.random.randint(1,len(X_test),len(X_test))\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if validation:\n",
    "    train_list =[]\n",
    "    for idx, batch in enumerate(zip(copy.deepcopy(X_train[train_idx]),\n",
    "                                    copy.deepcopy(np.concatenate([class_v[train_idx], X_obj_train[train_idx]], axis=-1)),\n",
    "                                    copy.deepcopy(adj_train[train_idx]))):\n",
    "        edge_index, _ = dense_to_sparse(torch.from_numpy(batch[2]).cuda().float())\n",
    "        train_list.append(Data(x = torch.from_numpy(batch[0]).cuda().float(),\n",
    "                               y = torch.from_numpy(batch[1]).cuda().float(),\n",
    "                               edge_index = edge_index\n",
    "                                    )\n",
    "                         )\n",
    "\n",
    "    batch_train_loader = DataLoader(train_list, batch_size=batch_size)\n",
    "\n",
    "    val_list = []\n",
    "    for idx, batch in enumerate(zip(copy.deepcopy(X_train_val[val_idx]),\n",
    "                                    copy.deepcopy(np.concatenate([class_v_val[val_idx], X_obj_train_val[val_idx]], axis=-1)),\n",
    "                                    copy.deepcopy(adj_train_val[val_idx]))):\n",
    "        edge_index, _ = dense_to_sparse(torch.from_numpy(batch[2]).cuda().float())\n",
    "        val_list.append(Data(x = torch.from_numpy(batch[0]).cuda().float(),\n",
    "                             y = torch.from_numpy(batch[1]).cuda().float(),\n",
    "                             edge_index = edge_index\n",
    "                                    )\n",
    "                         )\n",
    "    batch_val_loader = DataLoader(val_list, batch_size=batch_size)\n",
    "\n",
    "else:\n",
    "    train_list =[]\n",
    "    for idx, batch in enumerate(zip(copy.deepcopy(X_train[train_idx]),\n",
    "                                    copy.deepcopy(np.concatenate([class_v[train_idx], X_obj_train[train_idx]], axis=-1)),\n",
    "                                    copy.deepcopy(adj_train[train_idx]))):\n",
    "        edge_index, _ = dense_to_sparse(torch.from_numpy(batch[2]).cuda())\n",
    "        train_list.append(Data(x = torch.from_numpy(batch[0]).cuda(),\n",
    "                               y = torch.from_numpy(batch[1]).cuda(),\n",
    "                               edge_index = edge_index\n",
    "                                    )\n",
    "                         )\n",
    "\n",
    "    for idx, batch in enumerate(zip(copy.deepcopy(X_train_val[val_idx]),\n",
    "                                    copy.deepcopy(np.concatenate([class_v_val[val_idx], X_obj_train_val[val_idx]], axis=-1)),\n",
    "                                    copy.deepcopy(adj_train_val[val_idx]))):\n",
    "        edge_index, _ = dense_to_sparse(torch.from_numpy(batch[2]).cuda())\n",
    "        train_list.append(Data(x = torch.from_numpy(batch[0]).cuda(),\n",
    "                             y = torch.from_numpy(batch[1]).cuda(),\n",
    "                             edge_index = edge_index\n",
    "                                    )\n",
    "                         )\n",
    "    batch_train_loader = DataLoader(train_list, batch_size=batch_size)\n",
    "\n",
    "    val_list = []\n",
    "    for idx, batch in enumerate(zip(copy.deepcopy(X_test[test_idx]),\n",
    "                                    copy.deepcopy(np.concatenate([class_v_test[test_idx], X_obj_test[test_idx]], axis=-1)), \n",
    "                                    copy.deepcopy(adj_test[test_idx]))):\n",
    "        edge_index, _ = dense_to_sparse(torch.from_numpy(batch[2]).cuda())\n",
    "        val_list.append(Data(x = torch.from_numpy(batch[0]).cuda(),\n",
    "                             y = torch.from_numpy(batch[1]).cuda(),\n",
    "                             edge_index = edge_index\n",
    "                                    )\n",
    "                         )\n",
    "    batch_val_loader = DataLoader(val_list, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
